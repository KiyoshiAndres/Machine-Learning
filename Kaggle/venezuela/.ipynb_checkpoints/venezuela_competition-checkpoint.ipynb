{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c442ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227b3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/kiyoshitakeuchi/Desktop/Machine Learning/store-sales-time-series-forecasting/\"\n",
    "file_name = \"train.csv\"\n",
    "test_file_name = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87bcd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>CELEBRATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>DELI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr        family  sales  onpromotion\n",
       "0   0  2013-01-01          1    AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1     BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1        BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1     BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1         BOOKS    0.0            0\n",
       "5   5  2013-01-01          1  BREAD/BAKERY    0.0            0\n",
       "6   6  2013-01-01          1   CELEBRATION    0.0            0\n",
       "7   7  2013-01-01          1      CLEANING    0.0            0\n",
       "8   8  2013-01-01          1         DAIRY    0.0            0\n",
       "9   9  2013-01-01          1          DELI    0.0            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(file_path + file_name)\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b74bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000893</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000894</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>CELEBRATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000895</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000896</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3000897</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>DELI</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr        family  onpromotion\n",
       "0  3000888  2017-08-16          1    AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1     BABY CARE            0\n",
       "2  3000890  2017-08-16          1        BEAUTY            2\n",
       "3  3000891  2017-08-16          1     BEVERAGES           20\n",
       "4  3000892  2017-08-16          1         BOOKS            0\n",
       "5  3000893  2017-08-16          1  BREAD/BAKERY           12\n",
       "6  3000894  2017-08-16          1   CELEBRATION            0\n",
       "7  3000895  2017-08-16          1      CLEANING           25\n",
       "8  3000896  2017-08-16          1         DAIRY           45\n",
       "9  3000897  2017-08-16          1          DELI           18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"sales\"\n",
    "test_set = pd.read_csv(file_path + test_file_name)\n",
    "test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566c225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_string(data_frame):\n",
    "    for column in data_frame:\n",
    "        if column.name in numerical_categorical_features:\n",
    "            column.to_string()\n",
    "    return\n",
    "\n",
    "def remove_nan(data_frame): \n",
    "    mean = data_frame.select_dtypes(include = 'number').median()\n",
    "    mean = mean.to_dict()\n",
    "    data_frame.fillna(value=mean, inplace=True)\n",
    "    data_frame.fillna(value=\"?\", inplace=True)\n",
    "    return\n",
    "\n",
    "convert_to_string(test_set)\n",
    "convert_to_string(train_set)\n",
    "\n",
    "remove_nan(test_set)\n",
    "remove_nan(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8808dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_set.copy()\n",
    "labels = features.pop(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22e1c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_categorical_features = [\"store_nbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36774eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_frame):    \n",
    "    inputs = {}\n",
    "\n",
    "    for name, column in data_frame.items():\n",
    "        dtype = column.dtype\n",
    "        if dtype == object:\n",
    "            dtype = tf.string\n",
    "        else:\n",
    "            dtype = tf.float32\n",
    "        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "        \n",
    "    numeric_inputs = {name:input for name, input in inputs.items() \n",
    "                      if input.dtype==tf.float32}\n",
    "\n",
    "\n",
    "    x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "    norm = layers.Normalization()\n",
    "    norm.adapt(np.array(train_set[numeric_inputs.keys()]))\n",
    "    all_numeric_inputs = norm(x)\n",
    "\n",
    "    preprocessed_inputs = [all_numeric_inputs]\n",
    "    \n",
    "    for name, input in inputs.items():\n",
    "        if input.dtype == tf.float32:\n",
    "            continue \n",
    "\n",
    "        lookup = layers.StringLookup(vocabulary=np.unique(data_frame[name]))\n",
    "        one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "        x = lookup(input)\n",
    "        x = one_hot(x)\n",
    "        preprocessed_inputs.append(x)\n",
    "    \n",
    "    preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "    preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "    \n",
    "    return [inputs, preprocessing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3262e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiyoshitakeuchi/miniforge3/envs/test_name/lib/python3.8/site-packages/numpy/core/numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_array \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [124]\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data_frame)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m tf\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m \n\u001b[0;32m---> 27\u001b[0m lookup \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringLookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mCategoryEncoding(num_tokens\u001b[38;5;241m=\u001b[39mlookup\u001b[38;5;241m.\u001b[39mvocabulary_size())\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m lookup(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/keras/layers/preprocessing/string_lookup.py:326\u001b[0m, in \u001b[0;36mStringLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, idf_weights, encoding, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m   encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m encoding\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mStringLookup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_oov_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_oov_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43moov_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moov_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocabulary_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midf_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_max_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_max_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m base_preprocessing_layer\u001b[38;5;241m.\u001b[39mkeras_kpl_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStringLookup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py:289\u001b[0m, in \u001b[0;36mIndexLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary_dtype, vocabulary, idf_weights, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf_weights_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf_weights\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocabulary \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midf_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m   \u001b[38;5;66;03m# When restoring from a keras SavedModel, the loading code will expect to\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   \u001b[38;5;66;03m# find and restore a lookup_table attribute on the layer. This table needs\u001b[39;00m\n\u001b[1;32m    293\u001b[0m   \u001b[38;5;66;03m# to be uninitialized as a StaticHashTable cannot be initialized twice.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uninitialized_lookup_table()\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py:485\u001b[0m, in \u001b[0;36mIndexLookup.set_vocabulary\u001b[0;34m(self, vocabulary, idf_weights)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (new_vocab_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens):\n\u001b[1;32m    481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to set a vocabulary larger than the maximum vocab size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassed vocab size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, max vocab size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    484\u001b[0m           new_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens))\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup_table_from_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode \u001b[38;5;241m==\u001b[39m TF_IDF:\n\u001b[1;32m    488\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m idf_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py:704\u001b[0m, in \u001b[0;36mIndexLookup._lookup_table_from_tokens\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    702\u001b[0m indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrange(token_start, token_end, dtype\u001b[38;5;241m=\u001b[39mindices_dtype)\n\u001b[1;32m    703\u001b[0m keys, values \u001b[38;5;241m=\u001b[39m (indices, tokens) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvert \u001b[38;5;28;01melse\u001b[39;00m (tokens, indices)\n\u001b[0;32m--> 704\u001b[0m initializer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKeyValueTensorInitializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mlookup\u001b[38;5;241m.\u001b[39mStaticHashTable(initializer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_value)\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/ops/lookup_ops.py:549\u001b[0m, in \u001b[0;36mKeyValueTensorInitializer.__init__\u001b[0;34m(self, keys, values, key_dtype, value_dtype, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    547\u001b[0m         values, dtype\u001b[38;5;241m=\u001b[39mvalue_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    551\u001b[0m       values, dtype\u001b[38;5;241m=\u001b[39mvalue_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_value_init\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1691\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1692\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1695\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1698\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniforge3/envs/test_name/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "test_array = preprocess_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "decfeb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data_frame):\n",
    "    body = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "    \n",
    "    inputs, preprocessing_head = preprocess_data(data_frame)\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "    \n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dffbfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name: np.array(value) \n",
    "                         for name, value in features.items()}\n",
    "test_features_dict = {name: np.array(value) \n",
    "                         for name, value in test_set.copy().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "93baddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6439623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "481/481 [==============================] - 9s 19ms/step - loss: 72.7733 - val_loss: 224.4517\n",
      "Epoch 2/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 72.4561 - val_loss: 217.7624\n",
      "Epoch 3/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 72.0082 - val_loss: 217.9106\n",
      "Epoch 4/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 71.7618 - val_loss: 221.4492\n",
      "Epoch 5/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 71.6066 - val_loss: 224.9635\n",
      "Epoch 6/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 71.2946 - val_loss: 225.1965\n",
      "Epoch 7/10\n",
      "481/481 [==============================] - 9s 19ms/step - loss: 70.7980 - val_loss: 212.0665\n",
      "Epoch 8/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 70.7342 - val_loss: 218.3468\n",
      "Epoch 9/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 70.4646 - val_loss: 217.0769\n",
      "Epoch 10/10\n",
      "481/481 [==============================] - 9s 18ms/step - loss: 70.2171 - val_loss: 224.1021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2efacc790>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=features_dict, y=labels, validation_split = 0.2, batch_size=5000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0859c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = model.predict(test_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c164892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('venezuela_solution_6.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['id', 'sales']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    n = 3000888\n",
    "    for element in array:\n",
    "        writer.writerow({'id': n, 'sales': element[0]})\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae53bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef085c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
